{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b7cec7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/maximilianvogel/python/hippybees_AI'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "527afc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "os.getcwd()\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True' # sonst raucht der Kernel auf dem Macbook Pro ab\n",
    "\n",
    "# first neural network with keras tutorial\n",
    "# from numpy import loadtxt\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1acc43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bdc4fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [0.96 0.05]\n",
      " [0.05 0.97]\n",
      " [0.09 0.94]\n",
      " [0.52 0.53]\n",
      " [0.52 0.53]\n",
      " [0.63 0.73]\n",
      " [0.63 0.73]\n",
      " [0.95 0.45]\n",
      " [0.39 1.09]\n",
      " [0.7  0.8 ]\n",
      " [0.53 0.56]\n",
      " [0.53 0.56]\n",
      " [0.65 0.6 ]\n",
      " [0.58 0.67]\n",
      " [0.66 0.77]\n",
      " [0.12 0.13]\n",
      " [0.12 0.13]\n",
      " [0.11 0.94]\n",
      " [0.93 0.12]\n",
      " [0.93 0.12]\n",
      " [0.85 0.35]\n",
      " [0.31 0.9 ]\n",
      " [0.63 0.73]\n",
      " [0.64 0.75]\n",
      " [0.   1.2 ]\n",
      " [1.2  0.  ]\n",
      " [0.7  0.  ]\n",
      " [0.   0.7 ]\n",
      " [0.12 0.72]\n",
      " [0.07 0.08]\n",
      " [0.07 0.08]\n",
      " [0.07 0.08]\n",
      " [0.45 0.89]\n",
      " [0.   1.  ]]\n",
      "###\n",
      "[[0.66 0.77]\n",
      " [0.45 0.65]\n",
      " [0.65 0.55]\n",
      " [0.83 0.52]\n",
      " [0.07 0.08]]\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (Dense)                (None, 2, 100)            10100     \n",
      "_________________________________________________________________\n",
      "h1 (Dense)                   (None, 2, 100)            10100     \n",
      "_________________________________________________________________\n",
      "h2 (Dense)                   (None, 2, 100)            10100     \n",
      "_________________________________________________________________\n",
      "h3 (Dense)                   (None, 2, 100)            10100     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 40,802\n",
      "Trainable params: 40,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 0.1752 - mae: 0.3144\n",
      "Epoch 2/100\n",
      "36/36 [==============================] - 0s 591us/step - loss: 0.0569 - mae: 0.1608\n",
      "Epoch 3/100\n",
      "36/36 [==============================] - 0s 634us/step - loss: 0.0444 - mae: 0.1546\n",
      "Epoch 4/100\n",
      "36/36 [==============================] - 0s 668us/step - loss: 0.0346 - mae: 0.1312\n",
      "Epoch 5/100\n",
      "36/36 [==============================] - 0s 635us/step - loss: 0.0376 - mae: 0.1346\n",
      "Epoch 6/100\n",
      "36/36 [==============================] - 0s 605us/step - loss: 0.0290 - mae: 0.1172\n",
      "Epoch 7/100\n",
      "36/36 [==============================] - 0s 627us/step - loss: 0.0298 - mae: 0.1160\n",
      "Epoch 8/100\n",
      "36/36 [==============================] - 0s 611us/step - loss: 0.0281 - mae: 0.1037\n",
      "Epoch 9/100\n",
      "36/36 [==============================] - 0s 635us/step - loss: 0.0259 - mae: 0.1006\n",
      "Epoch 10/100\n",
      "36/36 [==============================] - 0s 631us/step - loss: 0.0260 - mae: 0.1030\n",
      "Epoch 11/100\n",
      "36/36 [==============================] - 0s 618us/step - loss: 0.0264 - mae: 0.0976\n",
      "Epoch 12/100\n",
      "36/36 [==============================] - 0s 620us/step - loss: 0.0271 - mae: 0.0994\n",
      "Epoch 13/100\n",
      "36/36 [==============================] - 0s 593us/step - loss: 0.0238 - mae: 0.0947\n",
      "Epoch 14/100\n",
      "36/36 [==============================] - 0s 659us/step - loss: 0.0231 - mae: 0.0944\n",
      "Epoch 15/100\n",
      "36/36 [==============================] - 0s 597us/step - loss: 0.0243 - mae: 0.1004\n",
      "Epoch 16/100\n",
      "36/36 [==============================] - 0s 636us/step - loss: 0.0229 - mae: 0.0874\n",
      "Epoch 17/100\n",
      "36/36 [==============================] - 0s 651us/step - loss: 0.0229 - mae: 0.0935\n",
      "Epoch 18/100\n",
      "36/36 [==============================] - 0s 641us/step - loss: 0.0205 - mae: 0.0822\n",
      "Epoch 19/100\n",
      "36/36 [==============================] - 0s 643us/step - loss: 0.0225 - mae: 0.0904\n",
      "Epoch 20/100\n",
      "36/36 [==============================] - 0s 613us/step - loss: 0.0202 - mae: 0.0835\n",
      "Epoch 21/100\n",
      "36/36 [==============================] - 0s 661us/step - loss: 0.0198 - mae: 0.0763\n",
      "Epoch 22/100\n",
      "36/36 [==============================] - 0s 617us/step - loss: 0.0194 - mae: 0.0790\n",
      "Epoch 23/100\n",
      "36/36 [==============================] - 0s 665us/step - loss: 0.0209 - mae: 0.0813\n",
      "Epoch 24/100\n",
      "36/36 [==============================] - 0s 582us/step - loss: 0.0194 - mae: 0.0828\n",
      "Epoch 25/100\n",
      "36/36 [==============================] - 0s 569us/step - loss: 0.0195 - mae: 0.0813\n",
      "Epoch 26/100\n",
      "36/36 [==============================] - 0s 588us/step - loss: 0.0170 - mae: 0.0728\n",
      "Epoch 27/100\n",
      "36/36 [==============================] - 0s 575us/step - loss: 0.0183 - mae: 0.0796\n",
      "Epoch 28/100\n",
      "36/36 [==============================] - 0s 624us/step - loss: 0.0177 - mae: 0.0814\n",
      "Epoch 29/100\n",
      "36/36 [==============================] - 0s 600us/step - loss: 0.0194 - mae: 0.0813\n",
      "Epoch 30/100\n",
      "36/36 [==============================] - 0s 607us/step - loss: 0.0179 - mae: 0.0725\n",
      "Epoch 31/100\n",
      "36/36 [==============================] - 0s 618us/step - loss: 0.0155 - mae: 0.0694\n",
      "Epoch 32/100\n",
      "36/36 [==============================] - 0s 643us/step - loss: 0.0165 - mae: 0.0734\n",
      "Epoch 33/100\n",
      "36/36 [==============================] - 0s 599us/step - loss: 0.0163 - mae: 0.0667\n",
      "Epoch 34/100\n",
      "36/36 [==============================] - 0s 615us/step - loss: 0.0163 - mae: 0.0713\n",
      "Epoch 35/100\n",
      "36/36 [==============================] - 0s 602us/step - loss: 0.0134 - mae: 0.0616\n",
      "Epoch 36/100\n",
      "36/36 [==============================] - 0s 636us/step - loss: 0.0140 - mae: 0.0619\n",
      "Epoch 37/100\n",
      "36/36 [==============================] - 0s 607us/step - loss: 0.0141 - mae: 0.0581\n",
      "Epoch 38/100\n",
      "36/36 [==============================] - 0s 647us/step - loss: 0.0132 - mae: 0.0594\n",
      "Epoch 39/100\n",
      "36/36 [==============================] - 0s 645us/step - loss: 0.0131 - mae: 0.0568\n",
      "Epoch 40/100\n",
      "36/36 [==============================] - 0s 631us/step - loss: 0.0119 - mae: 0.0532\n",
      "Epoch 41/100\n",
      "36/36 [==============================] - 0s 603us/step - loss: 0.0116 - mae: 0.0568\n",
      "Epoch 42/100\n",
      "36/36 [==============================] - 0s 676us/step - loss: 0.0106 - mae: 0.0513\n",
      "Epoch 43/100\n",
      "36/36 [==============================] - 0s 697us/step - loss: 0.0112 - mae: 0.0511\n",
      "Epoch 44/100\n",
      "36/36 [==============================] - 0s 699us/step - loss: 0.0103 - mae: 0.0488\n",
      "Epoch 45/100\n",
      "36/36 [==============================] - 0s 704us/step - loss: 0.0119 - mae: 0.0566\n",
      "Epoch 46/100\n",
      "36/36 [==============================] - 0s 632us/step - loss: 0.0115 - mae: 0.0604\n",
      "Epoch 47/100\n",
      "36/36 [==============================] - 0s 605us/step - loss: 0.0112 - mae: 0.0614\n",
      "Epoch 48/100\n",
      "36/36 [==============================] - 0s 605us/step - loss: 0.0143 - mae: 0.0669\n",
      "Epoch 49/100\n",
      "36/36 [==============================] - 0s 664us/step - loss: 0.0144 - mae: 0.0622\n",
      "Epoch 50/100\n",
      "36/36 [==============================] - 0s 653us/step - loss: 0.0110 - mae: 0.0575\n",
      "Epoch 51/100\n",
      "36/36 [==============================] - 0s 645us/step - loss: 0.0121 - mae: 0.0617\n",
      "Epoch 52/100\n",
      "36/36 [==============================] - 0s 589us/step - loss: 0.0105 - mae: 0.0505\n",
      "Epoch 53/100\n",
      "36/36 [==============================] - 0s 582us/step - loss: 0.0119 - mae: 0.0500\n",
      "Epoch 54/100\n",
      "36/36 [==============================] - 0s 597us/step - loss: 0.0103 - mae: 0.0478\n",
      "Epoch 55/100\n",
      "36/36 [==============================] - 0s 558us/step - loss: 0.0112 - mae: 0.0476\n",
      "Epoch 56/100\n",
      "36/36 [==============================] - 0s 637us/step - loss: 0.0102 - mae: 0.0508\n",
      "Epoch 57/100\n",
      "36/36 [==============================] - 0s 631us/step - loss: 0.0134 - mae: 0.0612\n",
      "Epoch 58/100\n",
      "36/36 [==============================] - 0s 638us/step - loss: 0.0103 - mae: 0.0509\n",
      "Epoch 59/100\n",
      "36/36 [==============================] - 0s 653us/step - loss: 0.0099 - mae: 0.0512\n",
      "Epoch 60/100\n",
      "36/36 [==============================] - 0s 623us/step - loss: 0.0106 - mae: 0.0525\n",
      "Epoch 61/100\n",
      "36/36 [==============================] - 0s 645us/step - loss: 0.0107 - mae: 0.0474\n",
      "Epoch 62/100\n",
      "36/36 [==============================] - 0s 602us/step - loss: 0.0092 - mae: 0.0438\n",
      "Epoch 63/100\n",
      "36/36 [==============================] - 0s 592us/step - loss: 0.0100 - mae: 0.0441\n",
      "Epoch 64/100\n",
      "36/36 [==============================] - 0s 635us/step - loss: 0.0097 - mae: 0.0451\n",
      "Epoch 65/100\n",
      "36/36 [==============================] - 0s 600us/step - loss: 0.0090 - mae: 0.0445\n",
      "Epoch 66/100\n",
      "36/36 [==============================] - 0s 581us/step - loss: 0.0096 - mae: 0.0463\n",
      "Epoch 67/100\n",
      "36/36 [==============================] - 0s 569us/step - loss: 0.0102 - mae: 0.0471\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 565us/step - loss: 0.0111 - mae: 0.0480\n",
      "Epoch 69/100\n",
      "36/36 [==============================] - 0s 656us/step - loss: 0.0109 - mae: 0.0526\n",
      "Epoch 70/100\n",
      "36/36 [==============================] - 0s 588us/step - loss: 0.0098 - mae: 0.0487\n",
      "Epoch 71/100\n",
      "36/36 [==============================] - 0s 611us/step - loss: 0.0114 - mae: 0.0518\n",
      "Epoch 72/100\n",
      "36/36 [==============================] - 0s 612us/step - loss: 0.0128 - mae: 0.0547\n",
      "Epoch 73/100\n",
      "36/36 [==============================] - 0s 620us/step - loss: 0.0097 - mae: 0.0473\n",
      "Epoch 74/100\n",
      "36/36 [==============================] - 0s 651us/step - loss: 0.0099 - mae: 0.0518\n",
      "Epoch 75/100\n",
      "36/36 [==============================] - 0s 612us/step - loss: 0.0103 - mae: 0.0480\n",
      "Epoch 76/100\n",
      "36/36 [==============================] - 0s 599us/step - loss: 0.0091 - mae: 0.0424\n",
      "Epoch 77/100\n",
      "36/36 [==============================] - 0s 620us/step - loss: 0.0107 - mae: 0.0440\n",
      "Epoch 78/100\n",
      "36/36 [==============================] - 0s 621us/step - loss: 0.0091 - mae: 0.0435\n",
      "Epoch 79/100\n",
      "36/36 [==============================] - 0s 646us/step - loss: 0.0093 - mae: 0.0438\n",
      "Epoch 80/100\n",
      "36/36 [==============================] - 0s 607us/step - loss: 0.0104 - mae: 0.0467\n",
      "Epoch 81/100\n",
      "36/36 [==============================] - 0s 603us/step - loss: 0.0105 - mae: 0.0466\n",
      "Epoch 82/100\n",
      "36/36 [==============================] - 0s 567us/step - loss: 0.0092 - mae: 0.0414\n",
      "Epoch 83/100\n",
      "36/36 [==============================] - 0s 582us/step - loss: 0.0099 - mae: 0.0437\n",
      "Epoch 84/100\n",
      "36/36 [==============================] - 0s 612us/step - loss: 0.0089 - mae: 0.0400\n",
      "Epoch 85/100\n",
      "36/36 [==============================] - 0s 603us/step - loss: 0.0091 - mae: 0.0387\n",
      "Epoch 86/100\n",
      "36/36 [==============================] - 0s 619us/step - loss: 0.0083 - mae: 0.0333\n",
      "Epoch 87/100\n",
      "36/36 [==============================] - 0s 642us/step - loss: 0.0087 - mae: 0.0341\n",
      "Epoch 88/100\n",
      "36/36 [==============================] - 0s 645us/step - loss: 0.0085 - mae: 0.0322\n",
      "Epoch 89/100\n",
      "36/36 [==============================] - 0s 592us/step - loss: 0.0091 - mae: 0.0343\n",
      "Epoch 90/100\n",
      "36/36 [==============================] - 0s 595us/step - loss: 0.0094 - mae: 0.0374\n",
      "Epoch 91/100\n",
      "36/36 [==============================] - 0s 630us/step - loss: 0.0085 - mae: 0.0359\n",
      "Epoch 92/100\n",
      "36/36 [==============================] - 0s 689us/step - loss: 0.0090 - mae: 0.0410\n",
      "Epoch 93/100\n",
      "36/36 [==============================] - 0s 616us/step - loss: 0.0100 - mae: 0.0409\n",
      "Epoch 94/100\n",
      "36/36 [==============================] - 0s 662us/step - loss: 0.0095 - mae: 0.0437\n",
      "Epoch 95/100\n",
      "36/36 [==============================] - 0s 658us/step - loss: 0.0092 - mae: 0.0428\n",
      "Epoch 96/100\n",
      "36/36 [==============================] - 0s 666us/step - loss: 0.0089 - mae: 0.0383\n",
      "Epoch 97/100\n",
      "36/36 [==============================] - 0s 659us/step - loss: 0.0088 - mae: 0.0385\n",
      "Epoch 98/100\n",
      "36/36 [==============================] - 0s 637us/step - loss: 0.0087 - mae: 0.0359\n",
      "Epoch 99/100\n",
      "36/36 [==============================] - 0s 631us/step - loss: 0.0083 - mae: 0.0333\n",
      "Epoch 100/100\n",
      "36/36 [==============================] - 0s 622us/step - loss: 0.0094 - mae: 0.0343\n",
      "36/36 [==============================] - 0s 5ms/step\n",
      "Mean absolute error train: 0.0328\n",
      "4/4 [==============================] - 0s 420us/step\n",
      "Mean absolute error test: 0.1105\n",
      "### TRAIN ###\n",
      "0 [ 0.98 -0.02] [1. 0.]\n",
      "1 [-0.03  0.99] [0. 1.]\n",
      "2 [0.96 0.06] [0.96 0.05]\n",
      "3 [0.05 0.97] [0.05 0.97]\n",
      "4 [0.09 0.94] [0.09 0.94]\n",
      "5 [0.53 0.54] [0.52 0.53]\n",
      "6 [0.52 0.53] [0.52 0.53]\n",
      "7 [0.62 0.77] [0.63 0.73]\n",
      "8 [0.65 0.72] [0.63 0.73]\n",
      "9 [0.93 0.48] [0.95 0.45]\n",
      "10 [0.43 1.07] [0.39 1.09]\n",
      "11 [0.69 0.81] [0.7 0.8]\n",
      "12 [0.54 0.56] [0.53 0.56]\n",
      "13 [0.53 0.58] [0.53 0.56]\n",
      "14 [0.65 0.6 ] [0.65 0.6 ]\n",
      "15 [0.58 0.68] [0.58 0.67]\n",
      "16 [0.65 0.8 ] [0.66 0.77]\n",
      "17 [0.1  0.13] [0.12 0.13]\n",
      "18 [0.13 0.13] [0.12 0.13]\n",
      "19 [0.11 0.94] [0.11 0.94]\n",
      "20 [0.92 0.13] [0.93 0.12]\n",
      "21 [0.92 0.13] [0.93 0.12]\n",
      "22 [0.49 0.64] [0.85 0.35]\n",
      "23 [0.28 0.95] [0.31 0.9 ]\n",
      "24 [0.63 0.74] [0.63 0.73]\n",
      "25 [0.65 0.75] [0.64 0.75]\n",
      "26 [0.  1.2] [0.  1.2]\n",
      "27 [1.22 0.01] [1.2 0. ]\n",
      "28 [0.73 0.02] [0.7 0. ]\n",
      "29 [0.02 0.72] [0.  0.7]\n",
      "30 [0.11 0.74] [0.12 0.72]\n",
      "31 [0.06 0.09] [0.07 0.08]\n",
      "32 [0.06 0.09] [0.07 0.08]\n",
      "33 [0.07 0.09] [0.07 0.08]\n",
      "34 [0.44 0.93] [0.45 0.89]\n",
      "35 [0.49 0.64] [0. 1.]\n",
      "### TEST ###\n",
      "36 [0.66 0.7 ] [0.66 0.77]\n",
      "37 [0.56 0.7 ] [0.45 0.65]\n",
      "38 [0.51 0.55] [0.65 0.55]\n",
      "39 [0.49 0.34] [0.83 0.52]\n",
      "40 [0.1  0.09] [0.07 0.08]\n"
     ]
    }
   ],
   "source": [
    "datafile = open('../01_data/Test_01.json',)\n",
    "\n",
    "crops = 2\n",
    "pixels = 10 * 10\n",
    "\n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "dataset = json.load(datafile)\n",
    "\n",
    "# print (dataset)\n",
    "# print (dataset[0][\"field\"][1])\n",
    "# print (dataset[1][\"yield\"][0])\n",
    "\n",
    "# cleanly suck it up\n",
    "datasize = len (dataset)\n",
    "X = np.empty([datasize, crops, pixels]) # e.g. 30 data samples of a wheat and fababean configuration in a 10x10 field = 30 / 2 / 100 \n",
    "y = np.empty([datasize, crops])\n",
    "\n",
    "# bring data of datset in X, y\n",
    "for i, data_elem in enumerate (dataset): # data_elem = 1 learning sample \n",
    "    # print (\"***\", i,\"-\", elem)\n",
    "    for j, field in enumerate (data_elem[\"field\"]): \n",
    "        # print (\"###\",j, field)\n",
    "        X[i][j] = field \n",
    "    for j, yield_val in enumerate (data_elem[\"yield\"]): \n",
    "        # print (\"XXX\",j, yield_val)\n",
    "        y[i][j] = yield_val\n",
    "    \n",
    "splitter = 5; # number of test samples, always the last in the file\n",
    "    \n",
    "X_train = X[:datasize - splitter]\n",
    "y_train = y[:datasize - splitter]\n",
    "\n",
    "X_test = X[-splitter:]\n",
    "y_test = y[-splitter:]\n",
    "\n",
    "print (y_train) \n",
    "print (\"###\")\n",
    "print (y_test)\n",
    "print (\"###\")\n",
    "print (\"###\")\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_shape=(2,100), activation='relu',name=\"input\"))\n",
    "model.add(Dense(100, activation='relu', name=\"h1\"))\n",
    "model.add(Dense(100, activation='relu', name=\"h2\"))\n",
    "model.add(Dense(100, activation='relu', name=\"h3\"))\n",
    "model.add(Flatten(name=\"flatten\"))\n",
    "model.add(Dense(crops, name=\"output\"))\n",
    "model.summary ()\n",
    "\n",
    "# compile the keras model\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.1), loss='mean_absolute_error')\n",
    "# model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['accuracy'])\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae'])\n",
    "\n",
    "# fit the keras model on the dataset\n",
    "model.fit (X_train, y_train, epochs=100, batch_size=6)\n",
    "\n",
    "# evaluate the keras model\n",
    "_, mae = model.evaluate(X_train, y_train)\n",
    "print('Mean absolute error train: %.4f' % (mae))\n",
    "_, mae = model.evaluate(X_test [1:], y_test[1:])\n",
    "print('Mean absolute error test: %.4f' % (mae))\n",
    "\n",
    "# make class predictions with the model\n",
    "predictions = model.predict(X)\n",
    "# summarize the first cases\n",
    "# print (\"predictions:\", predictions)\n",
    "# print (\"y\", y)\n",
    "\n",
    "print (\"### TRAIN ###\")\n",
    "for i, elem in enumerate (predictions):\n",
    "    # for i, elem2 in enumerate (elem1):            \n",
    "    if i == datasize - splitter: \n",
    "        print (\"### TEST ###\")      \n",
    "    print(i, np.around(predictions[i], 2), y[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0ef50c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3f491523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6.    148.     72.     35.      0.     33.6     0.627  50.   ] [ 1.    85.    66.    29.     0.    26.6    0.351 31.   ]\n",
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_174 (Dense)            (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_175 (Dense)            (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_176 (Dense)            (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 21.0317 - accuracy: 0.3477\n",
      "Epoch 2/20\n",
      "768/768 [==============================] - 0s 188us/step - loss: 7.7701 - accuracy: 0.3971\n",
      "Epoch 3/20\n",
      "768/768 [==============================] - 0s 184us/step - loss: 2.3291 - accuracy: 0.5964\n",
      "Epoch 4/20\n",
      "768/768 [==============================] - 0s 177us/step - loss: 0.9945 - accuracy: 0.6224\n",
      "Epoch 5/20\n",
      "768/768 [==============================] - 0s 199us/step - loss: 0.7962 - accuracy: 0.6471\n",
      "Epoch 6/20\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.7396 - accuracy: 0.6302\n",
      "Epoch 7/20\n",
      "768/768 [==============================] - 0s 176us/step - loss: 0.7251 - accuracy: 0.6328\n",
      "Epoch 8/20\n",
      "768/768 [==============================] - 0s 173us/step - loss: 0.7047 - accuracy: 0.6484\n",
      "Epoch 9/20\n",
      "768/768 [==============================] - 0s 173us/step - loss: 0.7120 - accuracy: 0.6263\n",
      "Epoch 10/20\n",
      "768/768 [==============================] - 0s 169us/step - loss: 0.6769 - accuracy: 0.6458\n",
      "Epoch 11/20\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.6815 - accuracy: 0.6432\n",
      "Epoch 12/20\n",
      "768/768 [==============================] - 0s 173us/step - loss: 0.6639 - accuracy: 0.6523\n",
      "Epoch 13/20\n",
      "768/768 [==============================] - 0s 162us/step - loss: 0.6507 - accuracy: 0.6549\n",
      "Epoch 14/20\n",
      "768/768 [==============================] - 0s 172us/step - loss: 0.6546 - accuracy: 0.6641\n",
      "Epoch 15/20\n",
      "768/768 [==============================] - 0s 170us/step - loss: 0.6272 - accuracy: 0.6641\n",
      "Epoch 16/20\n",
      "768/768 [==============================] - 0s 170us/step - loss: 0.6265 - accuracy: 0.6615\n",
      "Epoch 17/20\n",
      "768/768 [==============================] - 0s 189us/step - loss: 0.6219 - accuracy: 0.6875\n",
      "Epoch 18/20\n",
      "768/768 [==============================] - 0s 186us/step - loss: 0.6206 - accuracy: 0.6888\n",
      "Epoch 19/20\n",
      "768/768 [==============================] - 0s 187us/step - loss: 0.6099 - accuracy: 0.6940\n",
      "Epoch 20/20\n",
      "768/768 [==============================] - 0s 219us/step - loss: 0.5993 - accuracy: 0.6979\n",
      "768/768 [==============================] - 0s 156us/step\n",
      "Accuracy: 69.53\n",
      "[6.0, 148.0, 72.0, 35.0, 0.0, 33.6, 0.627, 50.0] => 0 (expected 1)\n",
      "[1.0, 85.0, 66.0, 29.0, 0.0, 26.6, 0.351, 31.0] => 0 (expected 0)\n",
      "[8.0, 183.0, 64.0, 0.0, 0.0, 23.3, 0.672, 32.0] => 0 (expected 1)\n",
      "[1.0, 89.0, 66.0, 23.0, 94.0, 28.1, 0.167, 21.0] => 0 (expected 0)\n",
      "[0.0, 137.0, 40.0, 35.0, 168.0, 43.1, 2.288, 33.0] => 1 (expected 1)\n"
     ]
    }
   ],
   "source": [
    "# first neural network with keras tutorial\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# load the dataset\n",
    "dataset = loadtxt('../01_data/pima-indians-diabetes.data.csv', delimiter=',')\n",
    "# dataset = loadtxt('pima-indians-diabetes.data.csv', delimiter=',')\n",
    "# split into input (X) and output (y) variables\n",
    "X = dataset[:,0:8]\n",
    "y = dataset[:,8]\n",
    "\n",
    "print (X[0],X[1])\n",
    "\n",
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary ()\n",
    "\n",
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X, y, epochs=20, batch_size=10)\n",
    "\n",
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X, y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))\n",
    "\n",
    "#\n",
    "#\n",
    "\n",
    "# make class predictions with the model\n",
    "predictions = model.predict_classes(X)\n",
    "# summarize the first 5 cases\n",
    "for i in range(5):\n",
    "    print('%s => %d (expected %d)' % (X[i].tolist(), predictions[i], y[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
